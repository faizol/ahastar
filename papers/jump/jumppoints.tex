\section{Jump Points}
In the previous section we developed simple rules for pruning neighbours during 
individual node expansions. We now extend this idea in order to define a 
macro-step operator which speeds up optimal search by selectively expanding
only certain nodes on a grid map. We term these nodes \emph{jump points}.
\par
The basic idea is straightforward: we give a simple example in Figure 
\ref{fig:jumppoints}(a).
Here we observe that when moving straight there are many cases where
the expanded node has only a single successor.
Since this successor cannot improve any other nodes on the open list we 
propose to evaluate it immediately, thereby avoiding an unnecessary list
maintenance operation. 
If we keep moving in the same direction we can continue this process until we 
either reach a node with more than one successor (a jump point), which we add to the open list instead of the nodes whose evaluation we expedited, or we find an 
obstacle which indicates that further search in this direction is fruitless.
\par
In the remainder of this section we will develop a macro-step operator which 
speeds up node expansion by identifying jump point successors in the case of
both straight and diagonal moves. We begin by making precise the concept of a
jump point:

\begin{definition}
\label{def:jump}
A node $x$ is designated a jump point if it satisfies at least one of the following
conditions:
\begin{enumerate}
\item{$x$ is a node which, after pruning, is adjacent to at least one neighbour
whose evaluation is forced according to the rules in Section
\ref{sec:prunestraight} and Section \ref{sec:prunediagonal}.}
\item{$x$ is located on the same row or column of the grid as the goal.}
\item{$x$ has one or more successors which are themselves jump points.}
\end{enumerate}
\end{definition}

Note that we distinguish between a neighbour, which is immediately adjacent to
$x$ on the grid, and a successor which may not be. 
This is a fine but important distinction as in our work a neighbour can be a 
successor but the converse is not necessarily true.
Thus, when expand $x$, we will only consider its successors.


\subsection{Generating Successors}
The process by which we generate the set of successors necessary to expand a
node $x$ is given in Algorithm \ref{alg:successors}.
We start with the pruned set of neighbours immediately adjacent to $x$ (line 2).
Then, instead of immediately adding each neighbour $n$ to the set of successors
for $x$, we try to ``jump'' to a node that is further away but which lies in the 
same relative direction to $x$ as $n$ (lines 3:4). 
For example, if the edge $(x, n)$ constitutes a
straight move travelling \emph{right} from $x$, we look for a jump point among
the nodes immediately to the right of $x$.
If we find such a node, we add it to the set of successors instead of $n$.
In the case where we fail to find a jump point, we add nothing.
The process continues until the set of neighbours for $x$ is exhausted.

\input alg_jumpexpansion

\subsection{Jumping}
The process by which we identfy jump points is given in Algorithm
\ref{alg:jump}; it requires an initial node $x$, a direction of travel $dir$
(e.g. up, down, left right, etc) and the goal node $g$.
In rough overview, the algorithm attempts to establish whether $x$ has any 
jump point successors by stepping in the direction $dir$ and testing
if the node $n$ at that location satisfies the constraints outlined in 
Definition \ref{def:jump}.
When this is the case, $n$ is designated a jump point and returned (lines 5, 7
and 11).
When $n$ is not a jump node the algorithm recurses and steps again in direction
$dir$ but this time $n$ is the new initial node (line 12).
The recursion terminates when an obstacle is encountered and no further
steps can be taken (line 3).
Note that before each diagonal step the algorithm must first 
fail to detect any straight jump points (lines 9:11). 
This check corresponds to the third constraint of Definition \ref{def:jump} 
and is essential for preserving optimality.
We give an example of diagonal jump point identification in Figure
\ref{fig:jumppoints}(b).

\begin{figure}[tb]
       \begin{center}
		   \includegraphics[scale=0.35, trim = 10mm 10mm 10mm 0mm]
			{diagrams/jumppoints.png}
       \end{center}
	\vspace{-3pt}
       \caption{Examples of straight (a) and diagonal (b) jump points.
Dashed lines indicate a sequence of interim node evaluations that reached
a dead end. Strong lines indicate eventual successor nodes.}
       \label{fig:jumppoints}
\end{figure}

\subsection{Optimality}
In the following theorem we prove that search with jump points preserves
optimality. As with Theorem \ref{thm:pruning} we will show this is true
by an inductive argument over the $g$-value of an arbitrary node chosen
for expansion.

%\begin{theorem}
%\label{thm:jump}
%Each jump point, when expanded, has an optimal $g$-value.
%\end{theorem}
%\begin{proof}
%Let $x$ be an arbitrary jump point node selected for expansion and suppose, 
%for a contradiction, that $g(x)$ is sub-optimal. 
%For this to happen, the immediate predecessor of $x$ on the optimal path must
%have been expanded earlier and 
%
%Sketch: show that each pruning rule discards only neighbours
%which cannot belong to the optimal path for the problem at hand.
%Then, by induction, demonstrate that jump points have the same 
%property. 
%
%Complications:
% - jump points when passing the row or column associated with the goal
% - no jump points at the top of a row/column ending in an obstacle.
%\end{proof}
%
%


\begin{theorem}
Travelling from one jump point to another is optimal.
\end{theorem}
\begin{proof}
Sketch: let $\pi$ be an arbitrarily chosen optimal path on the grid. 
We will show that for each $\pi$ there exists a symmetric alternative $\pi'$
which has the same length and mentions only nodes that are jump points.
First, split the optimal path into a series of adjacent segments s.t. $\pi = \lbrace \pi_{0}, \ldots, \pi_{n}
\rbrace$. Each $\pi_{i} \in \pi$ is a subpath comprised of one or more
contiguous steps in the same direction (e.g. only steps ``up'' or ``down'' etc).
Next, rewrite $\pi$ to minimise the number of segments.
This is a simple greedy procedure which we outline in Algorithm
\ref{alg:segments}. The idea is to form an equivalent path where all steps in one direction are taken 
together rather than interleaved with steps in another direction. 
Thus, each node at the beginning and end of a segment is a turning point where 
the optimal path must change direction.
By Lemma \ref{lemma:turningpoints}, each such node is also a jump point and therefore 
expanded during search.
Since each path segment consists only of moves in a single direction
(straight or diagonal) we can optimally travel from the node at the start of a
segment to the node at the end by only inspecting, and not necessarily expanding, every node
in between.
\end{proof}
